{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATH 317 Lab Assignment 2   \n",
    "October 22, 2023  \n",
    "Thomas Cole, 260904382  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1**) sin(x) via power series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinx(x,n):\n",
    "    # intialize\n",
    "    sum = 0\n",
    "    term = 1\n",
    "    # loop through to generate terms\n",
    "    for i in range(n):\n",
    "        term = math.pow(-1, i) * math.pow(x, 2 * i + 1) / math.factorial(2 * i + 1)\n",
    "        sum += term\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code to Help Generate Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_errorplot(func,f_compare,x_input,max_n,n_step):\n",
    "\n",
    "    # generate ns\n",
    "    ns = np.arange(0,max_n,n_step)\n",
    "\n",
    "    # generate function values and comparison + errors\n",
    "    x_f = np.array([func(x_input,n) for n in ns])\n",
    "    x_fc = np.array([f_compare(x_input) for n in ns])\n",
    "    error = x_fc - x_f\n",
    "\n",
    "    es = list(abs(error))\n",
    "\n",
    "    # convert to log\n",
    "    for i in range(len(es)):\n",
    "        if(es[i] != 0):\n",
    "            es[i] = math.log(es[i])\n",
    "    \n",
    "    return ns,es "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx,math.sin,0.1,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx,math.sin,1,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx,math.sin,10,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx,math.sin,100,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx vs math.sin for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 0.1')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 1')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 10')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 100')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I have plotted the log of the error of our power series relative to that of math.sin(). The slope of these lines indicates the absolute error relative to n, that is relative to the number of steps we calculate in the power series. Since we are taking log(error), large negative values indicate the error is close to 0. We can see that for x = 0.1, the power series log error converges quickly and stays constant after about n = 10. For x = 1, we see a different story, where we have constant error across values of n. For x = 10, the power series behaves slightly worse than when x = 0.1. As we can see in the graph, it converges after about n = 25, but before that has substantial error. Lastly, as we might have expected the power series behaves fairly poorly for large values of x. Above, I have plotted x = 100, and we can see that the error grows nearly quadratically as we increase n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2**) sin(x) with argument reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1: Reduction to [0,2pi]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinx2(x,n):\n",
    "    # use that sinx has period of 2pi\n",
    "    sign = 1\n",
    "    # reduce to > 0\n",
    "    if x < 0:\n",
    "        sign = -1\n",
    "        x = -x\n",
    "\n",
    "    # reduce to 2pi\n",
    "    x = x % (2 *  math.pi)\n",
    "    \n",
    "    # sinx as above\n",
    "    sum = 0\n",
    "    term = 1\n",
    "    for i in range(n):\n",
    "        term = math.pow(-1, i) * math.pow(x, 2 * i + 1) / math.factorial(2 * i + 1)\n",
    "        sum += term\n",
    "    return sum*sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first consider the fairly obvious argument reduction to [0,2pi]. Since we saw the issues with the previous method for large values of x, this should particularly help when x > 2pi~6.28. I have plotted the same plots we saw above but with this new argument reduction procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx2,math.sin,0.1,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx2,math.sin,1,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx2,math.sin,10,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx2,math.sin,100,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx2 vs math.sinx for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 0.1')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 1')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 10')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 100')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, this only affects x > 6.28. We can see a particular improvement for x = 10 and x = 100. Specifically, we can see that the log of this error converges fairly well for n = 15. We see a complete change in the graph of x = 100. That said, we can do even better with our argument reduction which will be explored below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Reduction to [0,pi/2]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinx3(x,n):\n",
    "    # reduce greater than 0\n",
    "    sig = 1\n",
    "    if(x < 0):\n",
    "        sig = -1\n",
    "        x = -x \n",
    "    # reduction to pi/2\n",
    "    r = x // math.pi/2\n",
    "    x = x % (math.pi/2)\n",
    "    sign = (-1)**r\n",
    "\n",
    "    # sinx power series\n",
    "    sum = 0\n",
    "    term = 1\n",
    "    for i in range(n):\n",
    "        term = math.pow(-1, i) * math.pow(x, 2 * i + 1) / math.factorial(2 * i + 1)\n",
    "        sum += term\n",
    "    return sum*sign*sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve upon our previous argument reduction of [0,2pi] we can actually reduce the argument to [0,pi/2]. We do this by exploiting the fact that sin(x) is symmetric about x = n*pi/2. We will again explore the same graphs originally seen in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx3,math.sin,0.1,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx3,math.sin,1,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx3,math.sin,10,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx3,math.sin,100,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx3 vs math.sinx for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 0.1')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 1')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 10')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 100')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our second method improves significantly values of x > pi/2. Particularly, looking at x = 10 and x = 100, we see that our method now converges fairly well and quickly. We can see that they both converge for around n = 5. This is certainly an improvement to our previous two methods. Below we'll explore the accuracy of both methods for even larger values of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Comparison for large values of x**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1: Large X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx,math.sin,100,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx,math.sin,200,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx,math.sin,500,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx,math.sin,1000,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx vs math.sinx for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 100')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 200')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 500')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 1000')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Large X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx2,math.sin,100,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx2,math.sin,200,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx2,math.sin,500,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx2,math.sin,1000,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx2 vs math.sinx for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 100')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 200')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 500')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 1000')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3: Large X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(sinx3,math.sin,100,50,1)\n",
    "p2n, p2e = generate_errorplot(sinx3,math.sin,200,50,1)\n",
    "p3n, p3e = generate_errorplot(sinx3,math.sin,500,50,1)\n",
    "p4n, p4e = generate_errorplot(sinx3,math.sin,1000,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of sinx3 vs math.sinx for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 100')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 200')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 500')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 1000')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It becomes clear through these graphs that our final method, with argument reduction to [0,pi/2] performs the best and converges the fastest for large values of x. Particularly, when we compare the original sinx power series to our current method. For the analysis above, we should choose this final method as our final solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3**) ln(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Power Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnx(x,n):\n",
    "    # intialize\n",
    "    x = x - 1\n",
    "    sum = 0\n",
    "    \n",
    "    # loop through to get next terms\n",
    "    for i in range(1,n):\n",
    "        term = math.pow(-1,i+1)*math.pow(x,i)/i\n",
    "        sum += term\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we employ the basic power series computation of ln(x). I have included below the similar graphs as we saw for sin(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(lnx,math.log,0.1,50,1)\n",
    "p2n, p2e = generate_errorplot(lnx,math.log,1,50,1)\n",
    "p3n, p3e = generate_errorplot(lnx,math.log,10,50,1)\n",
    "p4n, p4e = generate_errorplot(lnx,math.log,100,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of logx vs math.log for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 0.1')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 1')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 10')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 100')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we should have expected the power series performs fairly well for small values of x, but again performs poorly for large values of x. We'll next explore argument reduction for lnx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguement Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnx_red(x,n):\n",
    "    # reduce if x > 2, via formula below\n",
    "    if (x > 2):\n",
    "        i = 0\n",
    "        while(x / 2**i > 1):\n",
    "            i += 1\n",
    "        r = x / 2**i\n",
    "        return i*lnx(2,n) + lnx(r,n)\n",
    "    # if x < 2, compute using power series\n",
    "    else:\n",
    "        return lnx(x,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we employ argument reduction for x >2. We can re-write ln(y), where y > 2 as y = r * 2^n. Then we have that log(y) = n*log(2) + log(r). I have included graphs below for the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1n, p1e = generate_errorplot(lnx_red,math.log,0.1,50,1)\n",
    "p2n, p2e = generate_errorplot(lnx_red,math.log,1,50,1)\n",
    "p3n, p3e = generate_errorplot(lnx_red,math.log,10,50,1)\n",
    "p4n, p4e = generate_errorplot(lnx_red,math.log,100,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of lnx_red vs math.log for various x and n')\n",
    "axs[0, 0].plot(p1n, p1e)\n",
    "axs[0, 0].set_title('log(error) for x = 0.1')\n",
    "axs[0, 1].plot(p2n, p2e, 'tab:orange')\n",
    "axs[0, 1].set_title('log(error) for x = 1')\n",
    "axs[1, 0].plot(p3n, p3e, 'tab:green')\n",
    "axs[1, 0].set_title('log(error) for x = 10')\n",
    "axs[1, 1].plot(p4n, p4e, 'tab:red')\n",
    "axs[1, 1].set_title('log(error) for x = 100')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this argument reduction procedure has helped significantly for large values of x. Instead of seeing the exponentially growing error relative to n we now see that our estimates get better as n increases. This is desirable. Thus, we choose this argument reduction procedure as our final method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4**) ln(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1: Basic Power Series with Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnx_red(3,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way we might choose to compute ln(3) would be through traditional power-series with argument reduction, as we have explored above. Though, as we know there are even faster ways to compute these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Gregory Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want ln3. We need 3 = (1+x)/(1-x) -> x = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gregory(x,n):\n",
    "    # intialize\n",
    "    sum = 0\n",
    "    \n",
    "    # calculate terms in gergory series\n",
    "    for i in range(0,n):\n",
    "        term = x**(2*i+1)/(2*i+1)\n",
    "        sum += term\n",
    "    return sum*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gregory(0.5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method here calculates ln(3) by employing gregory series with x = 0.5. We know that gregory series was specifically designed to converge faster than traditional ln(x) power series. Thus, we should expect this to perform fairly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3: Gregory with Reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = 2 / (4 + 2*sqrt(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 / (4 + 2*math.sqrt(3))\n",
    "2*gregory(x,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we provide a third method for computing ln(3) using argument reduction as given by equation 60 in the iteration notes. By this equation we have that ln(3) = 2*log(1+ z) where z = x / (1+ sqrt(1+x)). We solve for z = 2. This has been calculated and is given above. Since we have even further argument reduction, we should expect this method to converge the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 / (4 + 2*math.sqrt(3))\n",
    "# generate n\n",
    "ns = np.arange(1,100,1)\n",
    "\n",
    "# generate values for each method\n",
    "m1 = np.array([lnx_red(3,n) for n in ns])\n",
    "m2 = np.array([gregory(0.5,n) for n in ns])\n",
    "m3 = np.array([2*gregory(x,n) for n in ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(ns,m1,label = \"Method 1\")\n",
    "plt.plot(ns,m2, label = \"Method 2\")\n",
    "plt.plot(ns,m3, label = \"Method 3\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I have plotted the value outputs of each function for a given number of iterations (n) as this provides a clear understanding of the convergence speed of each of these methods. As we had hypothesized before, Method 1, the traditional power series with argument reduction converges the slowest. We can also see that Method 2, Gregory Series and Method 3, Gregory with further argument reduction converge at similar rates and certainly much faster than the traditional power series. These latter methods appear to only require a few steps to arrive at a suitable approximation of the true value. Thus, if one were to require fast computation of ln(3), Method 2 or 3 would be the best choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1) Goldschimdt and Heron**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goldschidmt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goldschidmt_sqrt(x,n,delta):\n",
    "    # intialize b and  y\n",
    "    b = x\n",
    "    y = x\n",
    "\n",
    "    # apply iteration formula\n",
    "    for i in range(n):\n",
    "        k = abs((3-b)) / 2\n",
    "        y = y*k\n",
    "        b = b*k**2\n",
    "\n",
    "        # add delta\n",
    "        b = b*(1+delta)\n",
    "        y = y*(1+delta)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Herons Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heron(a,n,delta):\n",
    "    # intialize starting value\n",
    "    x = a\n",
    "    # apply iteration formula\n",
    "    for i in range(n):\n",
    "        x = 1/2*(x + a/x)\n",
    "        # add delta\n",
    "        x = x*(1+delta)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I have defined the functions for computing the square root under both Heron's Method and Goldschidmts method, as seen in class. Note that I have also included a parameter delta, which adds error after each term in the computation. This parameter will be used to illustrate the self correcting nature of Heron's method, and the opposite for Goldschidmts method. \n",
    "\n",
    "In the graphs below, I have computed the log error of both methods, with a given delta of 10^(-3), and for various values of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_v_heron(x,delta):\n",
    "    # generate ns\n",
    "    ns = np.arange(10,1000,5)\n",
    "    delta = 10**(-3)\n",
    "    # generate values\n",
    "    heron_e = np.array([heron(x,n,delta) for n in ns])\n",
    "    gold_e  = np.array([goldschidmt_sqrt(x,n,delta) for n in ns])\n",
    "    actual = np.array([math.sqrt(x) for n in ns])\n",
    "\n",
    "    # calculate error\n",
    "    error_h = actual - heron_e\n",
    "    error_g = actual - gold_e\n",
    "\n",
    "    # log error\n",
    "    esh = list(np.log(abs(error_h)))\n",
    "    esg = list(np.log(abs(error_g)))\n",
    "\n",
    "    return esh,esg,ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 10**-3\n",
    "esh1,esg1,_  = gold_v_heron(0.5,delta)\n",
    "esh2,esg2,_  = gold_v_heron(1.5,delta)\n",
    "esh3,esg3,_ = gold_v_heron(2,delta)\n",
    "esh4,esg4,ns = gold_v_heron(2.5,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('log(error) of goldschimdt method and herons vs math.sqrt for various x and n')\n",
    "axs[0, 0].plot(ns, esg1,'tab:orange', label = \"Goldschidmt\")\n",
    "axs[0, 0].plot(ns, esh1,'tab:blue',label = \"Heron\")\n",
    "axs[0, 0].set_title('log(error) for x = 0.5')\n",
    "axs[0,0].legend(loc = \"upper left\")\n",
    "\n",
    "axs[0, 1].plot(ns, esg2, 'tab:orange')\n",
    "axs[0, 1].plot(ns, esh2, 'tab:blue')\n",
    "axs[0, 1].set_title('log(error) for x = 1.5')\n",
    "\n",
    "axs[1, 0].plot(ns, esg3, 'tab:orange')\n",
    "axs[1, 0].plot(ns, esh3, 'tab:blue')\n",
    "axs[1, 0].set_title('log(error) for x = 2')\n",
    "\n",
    "axs[1, 1].plot(ns, esg4, 'tab:orange')\n",
    "axs[1, 1].plot(ns, esh4, 'tab:blue')\n",
    "axs[1, 1].set_title('log(error) for x = 2.5')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='log(error)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see based on the graphs above, that when we add additional error within our computation, this error continues to compound and grow within Goldschidmts algorithm. The opposite effect can be seen in Heron's method, which appears constant. This displays what we know to be true, that is, Heron's method exhibits self-correcting behaviour while Goldschidmts algorithm does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided two methods below to approximate the smallest root of sin(x) = e^(-x). For the first method, we simply have x = arcsin(e^(-x)). We will show through graphs that this method is linearly convergent. The second method we employ Newton-Raphson and have x = x + (e^(-x) - sinx)/(e^(-x)+ cosx), which is quadratically convergent. When approximating the roots of this equation, we assume that the user knows the root should appear between [0,1]. For simplicity we choose 1 as our starting point for iteration, though any value in this region would be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_sin(a,n):\n",
    "    # intialize\n",
    "    x = a\n",
    "    # apply iterative formula\n",
    "    for i in range(n):\n",
    "        x = math.asin(math.exp(-x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_sin(1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_sin2(a,n):\n",
    "    # initialize\n",
    "    x = a\n",
    "    # apply iterative formula\n",
    "    for i in range(n):\n",
    "        x = x + (math.exp(-x) - math.sin(x))/(math.exp(-x) + math.cos(x))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_sin2(1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we compare the convergence speed of the two methods. It appears more obvious when we simply examine the behavior of these functions for varying values of n, and see how they approach the true value of the root. In doing this, we can get a clear picture of how the fixed point iterations behave and it allows us to compare their convergence speed.  Particularly, we examine their convergence speed for different initial values of x on the interval [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_root(x):\n",
    "    # intialize n range\n",
    "    ns = np.arange(1,50,1)\n",
    "    # get values for functions\n",
    "    fp_sin_v = np.array([fp_sin(x,n) for n in ns])\n",
    "    fp_sin2_v = np.array([fp_sin2(x,n) for n in ns])\n",
    "\n",
    "    return fp_sin_v,fp_sin2_v,ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1, fps1, _  = compare_root(0)\n",
    "fp2, fps2, _  = compare_root(0.25)\n",
    "fp3, fps3, _  = compare_root(0.5)\n",
    "fp4, fps4, ns = compare_root(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('Method 1 vs Method 2 for calculating roots')\n",
    "axs[0, 0].plot(ns, fp1,'tab:orange', label = \"Method 1\")\n",
    "axs[0, 0].plot(ns, fps1,'tab:blue',label = \"Method 2\")\n",
    "axs[0, 0].set_title('x = 0')\n",
    "axs[0,0].legend(loc = \"upper left\")\n",
    "\n",
    "axs[0, 1].plot(ns, fp2, 'tab:orange')\n",
    "axs[0, 1].plot(ns, fps2, 'tab:blue')\n",
    "axs[0, 1].set_title('x = 0.25')\n",
    "\n",
    "axs[1, 0].plot(ns, fp3, 'tab:orange')\n",
    "axs[1, 0].plot(ns, fps3, 'tab:blue')\n",
    "axs[1, 0].set_title('x = 0.5')\n",
    "\n",
    "axs[1, 1].plot(ns, fp4, 'tab:orange')\n",
    "axs[1, 1].plot(ns, fps4, 'tab:blue')\n",
    "axs[1, 1].set_title('x = 1')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='n', ylabel='f(x)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the graphs above we can see that method 1 converges much slower for different values of x. We see most often that it converges after about n = 15. We see a different behavior in Method 2, which is quadratically convergent. This method clearly converges much faster to the appropriate root. Most interestingly, even if we make a good starting guess such as x = 0.5, which is fairly close to our root, Method 1 still takes a while to converge to the appropriate root of ~0.5885, where as Method 2 converges with very few steps. That said, it is also clear from the graphs that both methods do indeed converge after about n = 20 consistently. These graphics show that the methods we determined do indeed have the desired convergence orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_cos3x(y_0,a,n):\n",
    "    # intialize starting value\n",
    "    y = y_0\n",
    "    \n",
    "    # apply iterative formula\n",
    "    for i in range(n):\n",
    "        y = y - (4*y**3 - 3*y -a)/(12*y**2-3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We design an algorithm to compute the root of 4y^3 -3y = a by employing Newton-Raphson. Once we have this iterative formula, we apply it for the given input parameter n. If the user wants to compute cos(x) through using cos(3x), we assume they know the value of cos(3x) for the angle they would like to trisect. \n",
    "\n",
    "Given that this method is designed through Newton-Raphson, we know it should be at least quadratically convergent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example sin20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compute sin(20), we know that cos(60) = 0.5. Thus we input that as our parameter a. We can then use the trig identity sin^2x + cos^2x = 1 to retrieve the value of sin(20). That is, we first trisect the angle 60 using our iterative formula and then apply the trig identity to go from cos(20) to sin(20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cos3x(10,0.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(1- nr_cos3x(100,0.5,100)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize n\n",
    "ns = np.arange(7,50,1)\n",
    "# get values for each function\n",
    "sinx3_v = np.array([sinx3(math.pi/9,n) for n in ns])\n",
    "sinxp3_v = np.array([nr_cos3x(10,0.5,n) for n in ns])\n",
    "actual = np.array([math.sin(math.pi/9) for n in ns])\n",
    "sinxp3_vs = np.sqrt(1-sinxp3_v**2)\n",
    "\n",
    "# get log(error)\n",
    "diff1 = np.log(abs(sinx3_v - actual))\n",
    "diff2 = np.log(abs(sinxp3_vs - actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(ns,diff1, label = \"sinx3 vs math.sin\")\n",
    "plt.plot(ns,diff2, label = 'trisecting vs math.sin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by the graph above, our trisecting angle formula works decently well once n > 10. That said, we still see some differences between the true value of sin(20) and our computed value. We see minor oscillations in the log(error) for this method, but our error overall is still fairly close to 0. Relative to our sinx computation with argument reduction in Part 1 however, this method under performs. We can see that our sin(x) method converges close to the true value after very few iterations and stays constant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
